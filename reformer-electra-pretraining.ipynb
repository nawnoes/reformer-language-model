{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"reformer-electra-pretraining.ipynb","provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyOSRQPK1Oqo4CeA4G785ew/"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"eGlc-gSSHxMG"},"source":["## Google Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_EepZFND2Wa","executionInfo":{"status":"ok","timestamp":1610583202146,"user_tz":-540,"elapsed":30515,"user":{"displayName":"Seonghwan Kim","photoUrl":"https://lh3.googleusercontent.com/-hgV3WUwRu5o/AAAAAAAAAAI/AAAAAAAAABo/_YWLMr5poWs/s64/photo.jpg","userId":"17497395371430681608"}},"outputId":"2f633d6c-b5ae-4c80-9f72-6a802dd4e65e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4YmkCMshH1GP"},"source":["## Install Package"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6GVAFahBLBsb","executionInfo":{"status":"ok","timestamp":1610583250381,"user_tz":-540,"elapsed":78742,"user":{"displayName":"Seonghwan Kim","photoUrl":"https://lh3.googleusercontent.com/-hgV3WUwRu5o/AAAAAAAAAAI/AAAAAAAAABo/_YWLMr5poWs/s64/photo.jpg","userId":"17497395371430681608"}},"outputId":"6f8593dd-87f6-41a7-ece0-2ec98252d925"},"source":["!pip install -r \"/content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 1)) (1.7.0+cu101)\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/ea/634945faff8ad6984b98f7f3d98f6d83083a18af44e349744d90bde81f80/transformers-4.2.0-py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 12.7MB/s \n","\u001b[?25hCollecting reformer_pytorch==1.2.4\n","  Downloading https://files.pythonhosted.org/packages/8a/16/e84a99e6d34b616ab95ed6ab8c1b76f0db50e3beea854879384602e50e54/reformer_pytorch-1.2.4-py3-none-any.whl\n","Collecting electra-pytorch\n","  Downloading https://files.pythonhosted.org/packages/38/a4/b1484566695354028cfc4d01df520d8590e6fb0791594977f1bfdf275ebb/electra_pytorch-0.1.1-py3-none-any.whl\n","Collecting kss\n","  Downloading https://files.pythonhosted.org/packages/55/52/e3216b68094a73c39dfb037f4f2f5ba21177e8178f334829f985dbf12194/kss-2.2.0.2-py3-none-any.whl\n","Collecting fairseq==0.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n","\u001b[K     |████████████████████████████████| 307kB 56.3MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 1)) (0.16.0)\n","Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 1)) (0.8)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 1)) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 1)) (3.7.4.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (20.8)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 49.5MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 61.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (3.3.0)\n","Collecting local-attention\n","  Downloading https://files.pythonhosted.org/packages/5b/37/f8702c01f3f2af43a967d6a45bca88529f8fdaa6fc2175377bf8ca2000ee/local_attention-1.2.1-py3-none-any.whl\n","Collecting product-key-memory\n","  Downloading https://files.pythonhosted.org/packages/31/3b/c1f8977e4b04f047acc7b23c7424d1e2e624ed7031e699a2ac2287af4c1f/product_key_memory-0.1.10.tar.gz\n","Collecting axial-positional-embedding>=0.1.0\n","  Downloading https://files.pythonhosted.org/packages/7a/27/ad886f872b15153905d957a70670efe7521a07c70d324ff224f998e52492/axial_positional_embedding-0.2.1.tar.gz\n","Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from electra-pytorch->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 4)) (0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from electra-pytorch->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 4)) (1.4.1)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 6)) (1.14.4)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 6)) (0.29.21)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 2)) (3.4.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->electra-pytorch->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 4)) (0.22.2.post1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.9.0->-r /content/drive/My Drive/Colab Notebooks/reformer-language-model/requirements.txt (line 6)) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Building wheels for collected packages: fairseq, sacremoses, product-key-memory, axial-positional-embedding\n","  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2064579 sha256=2c6c33c06925cb820d77eb1a2a992880eb0aee95cdf18fb6faba0e0becb768ab\n","  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=38cfb222a7c3ac8a7ffe1ded9d195b52d7896fb11b183e3d609e5bbae70b49fc\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","  Building wheel for product-key-memory (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for product-key-memory: filename=product_key_memory-0.1.10-cp36-none-any.whl size=3072 sha256=a79ed11fee6c3decd7286d912526b9462452ba1e24700ad27795aa43deabc71b\n","  Stored in directory: /root/.cache/pip/wheels/6d/e0/3b/fd3111a4fac652ed014ccfd4757754f006132723985e229419\n","  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-cp36-none-any.whl size=2904 sha256=c6ffb669aeee5e79035de78ef9380304910559f2d288d6213debc08fc18c3a0d\n","  Stored in directory: /root/.cache/pip/wheels/cd/f8/93/25b60e319a481e8f324dcb1871aff818eb0c8143ed20b732b4\n","Successfully built fairseq sacremoses product-key-memory axial-positional-embedding\n","\u001b[31mERROR: electra-pytorch 0.1.1 has requirement transformers==3.0.2, but you'll have transformers 4.2.0 which is incompatible.\u001b[0m\n","Installing collected packages: tokenizers, sacremoses, transformers, local-attention, product-key-memory, axial-positional-embedding, reformer-pytorch, electra-pytorch, kss, portalocker, sacrebleu, fairseq\n","Successfully installed axial-positional-embedding-0.2.1 electra-pytorch-0.1.1 fairseq-0.9.0 kss-2.2.0.2 local-attention-1.2.1 portalocker-2.0.0 product-key-memory-0.1.10 reformer-pytorch-1.2.4 sacrebleu-1.4.14 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EyBWke0LutbH"},"source":["## Pretraining"]},{"cell_type":"code","metadata":{"id":"aE_tCBv8uroC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610613548238,"user_tz":-540,"elapsed":30376596,"user":{"displayName":"Seonghwan Kim","photoUrl":"https://lh3.googleusercontent.com/-hgV3WUwRu5o/AAAAAAAAAAI/AAAAAAAAABo/_YWLMr5poWs/s64/photo.jpg","userId":"17497395371430681608"}},"outputId":"c3ebc304-1a68-4e0f-c652-6d5582a7b6b2"},"source":["!python3 \"/content/drive/My Drive/Colab Notebooks/reformer-language-model/pretrain/electra-model.py\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["100% 3/3 [02:08<00:00, 42.88s/it]\n","Epoch-0 Iterator: |          | 105803/? [4:48:39<00:00,  4.01s/it, 2021-01-14 05:05:37.916545 | Train Loss: 12.671985149383545 | Steps: 105802]\n","Epoch-1 Iterator:   0% 0/105802 [00:00<?, ?it/s]\u001b[A\n","Epoch-1 Iterator:   0% 0/105802 [00:03<?, ?it/s, 2021-01-14 08:29:49.257279 | Train Loss: 13.855957508087158 | Steps: 105804]\u001b[A\n","Epoch-1 Iterator:   0% 1/105802 [00:04<122:05:38,  4.15s/it, 2021-01-14 08:29:49.257279 | Train Loss: 13.855957508087158 | Steps: 105804]\u001b[A\n","Epoch-1 Iterator:   0% 2/105802 [00:07<116:34:07,  3.97s/it, 2021-01-14 08:29:49.257279 | Train Loss: 13.855957508087158 | Steps: 105804]\u001b[A\n","Epoch-1 Iterator:   0% 2/105802 [00:11<116:34:07,  3.97s/it, 2021-01-14 08:29:56.589932 | Train Loss: 13.453721046447754 | Steps: 105806]\u001b[A\n","Epoch-1 Iterator:   0% 3/105802 [00:11<115:11:51,  3.92s/it, 2021-01-14 08:29:56.589932 | Train Loss: 13.453721046447754 | Steps: 105806]\u001b[A\n","Epoch-1 Iterator:   0% 4/105802 [00:15<111:52:28,  3.81s/it, 2021-01-14 08:29:56.589932 | Train Loss: 13.453721046447754 | Steps: 105806]\u001b[A\n","Epoch-1 Iterator:   0% 4/105802 [00:18<111:52:28,  3.81s/it, 2021-01-14 08:30:03.958456 | Train Loss: 13.30873155593872 | Steps: 105808] \u001b[A\n","Epoch-1 Iterator:   0% 5/105802 [00:18<112:13:44,  3.82s/it, 2021-01-14 08:30:03.958456 | Train Loss: 13.30873155593872 | Steps: 105808]\u001b[A\n","Epoch-1 Iterator:   0% 6/105802 [00:22<109:49:18,  3.74s/it, 2021-01-14 08:30:03.958456 | Train Loss: 13.30873155593872 | Steps: 105808]\u001b[A\n","Epoch-1 Iterator:   0% 6/105802 [00:25<109:49:18,  3.74s/it, 2021-01-14 08:30:11.346288 | Train Loss: 13.2173490524292 | Steps: 105810] \u001b[A\n","Epoch-1 Iterator:   0% 7/105802 [00:26<110:34:34,  3.76s/it, 2021-01-14 08:30:11.346288 | Train Loss: 13.2173490524292 | Steps: 105810]\u001b[A\n","Epoch-1 Iterator:   0% 8/105802 [00:29<108:49:02,  3.70s/it, 2021-01-14 08:30:11.346288 | Train Loss: 13.2173490524292 | Steps: 105810]\u001b[A\n","Epoch-1 Iterator:   0% 8/105802 [00:33<108:49:02,  3.70s/it, 2021-01-14 08:30:18.754303 | Train Loss: 12.881726264953613 | Steps: 105812]\u001b[A\n","Epoch-1 Iterator:   0% 9/105802 [00:33<109:58:20,  3.74s/it, 2021-01-14 08:30:18.754303 | Train Loss: 12.881726264953613 | Steps: 105812]\u001b[A\n","Epoch-1 Iterator:   0% 10/105802 [00:37<108:00:35,  3.68s/it, 2021-01-14 08:30:18.754303 | Train Loss: 12.881726264953613 | Steps: 105812]\u001b[A\n","Epoch-1 Iterator:   0% 10/105802 [00:40<108:00:35,  3.68s/it, 2021-01-14 08:30:26.079255 | Train Loss: 13.147600650787354 | Steps: 105814]\u001b[A\n","Epoch-1 Iterator:   0% 11/105802 [00:40<109:11:46,  3.72s/it, 2021-01-14 08:30:26.079255 | Train Loss: 13.147600650787354 | Steps: 105814]\u001b[A\n","Epoch-1 Iterator:   0% 12/105802 [00:44<107:34:49,  3.66s/it, 2021-01-14 08:30:26.079255 | Train Loss: 13.147600650787354 | Steps: 105814]\u001b[A\n","Epoch-1 Iterator:   0% 12/105802 [00:48<107:34:49,  3.66s/it, 2021-01-14 08:30:33.478909 | Train Loss: 12.975158214569092 | Steps: 105816]\u001b[A\n","Epoch-1 Iterator:   0% 13/105802 [00:48<109:24:03,  3.72s/it, 2021-01-14 08:30:33.478909 | Train Loss: 12.975158214569092 | Steps: 105816]\u001b[A\n","Epoch-1 Iterator:   0% 14/105802 [00:51<107:42:14,  3.67s/it, 2021-01-14 08:30:33.478909 | Train Loss: 12.975158214569092 | Steps: 105816]\u001b[A\n","Epoch-1 Iterator:   0% 14/105802 [00:55<107:42:14,  3.67s/it, 2021-01-14 08:30:40.869197 | Train Loss: 13.479399681091309 | Steps: 105818]\u001b[A\n","Epoch-1 Iterator:   0% 15/105802 [00:55<109:30:35,  3.73s/it, 2021-01-14 08:30:40.869197 | Train Loss: 13.479399681091309 | Steps: 105818]\u001b[A\n","Epoch-1 Iterator:   0% 16/105802 [00:59<107:46:27,  3.67s/it, 2021-01-14 08:30:40.869197 | Train Loss: 13.479399681091309 | Steps: 105818]\u001b[A\n","Epoch-1 Iterator:   0% 16/105802 [01:02<107:46:27,  3.67s/it, 2021-01-14 08:30:48.254057 | Train Loss: 13.082775115966797 | Steps: 105820]\u001b[A\n","Epoch-1 Iterator:   0% 17/105802 [01:03<109:27:34,  3.73s/it, 2021-01-14 08:30:48.254057 | Train Loss: 13.082775115966797 | Steps: 105820]\u001b[A\n","Epoch-1 Iterator:   0% 18/105802 [01:06<107:56:34,  3.67s/it, 2021-01-14 08:30:48.254057 | Train Loss: 13.082775115966797 | Steps: 105820]\u001b[A\n","Epoch-1 Iterator:   0% 18/105802 [01:10<107:56:34,  3.67s/it, 2021-01-14 08:30:55.664335 | Train Loss: 13.011415004730225 | Steps: 105822]\u001b[A\n","Epoch-1 Iterator:   0% 19/105802 [01:10<109:32:54,  3.73s/it, 2021-01-14 08:30:55.664335 | Train Loss: 13.011415004730225 | Steps: 105822]\u001b[A\n","Epoch-1 Iterator:   0% 20/105802 [01:14<107:53:02,  3.67s/it, 2021-01-14 08:30:55.664335 | Train Loss: 13.011415004730225 | Steps: 105822]\u001b[A\n","Epoch-1 Iterator:   0% 20/105802 [01:17<107:53:02,  3.67s/it, 2021-01-14 08:31:03.031979 | Train Loss: 13.028316974639893 | Steps: 105824]\u001b[A\n","Epoch-1 Iterator:   0% 21/105802 [01:17<109:10:11,  3.72s/it, 2021-01-14 08:31:03.031979 | Train Loss: 13.028316974639893 | Steps: 105824]\u001b[A\n","Epoch-1 Iterator:   0% 22/105802 [01:21<107:35:49,  3.66s/it, 2021-01-14 08:31:03.031979 | Train Loss: 13.028316974639893 | Steps: 105824]\u001b[A\n","Epoch-1 Iterator:   0% 22/105802 [01:24<107:35:49,  3.66s/it, 2021-01-14 08:31:10.378671 | Train Loss: 12.779664993286133 | Steps: 105826]\u001b[A\n","Epoch-1 Iterator:   0% 23/105802 [01:25<108:58:28,  3.71s/it, 2021-01-14 08:31:10.378671 | Train Loss: 12.779664993286133 | Steps: 105826]\u001b[A\n","Epoch-1 Iterator:   0% 24/105802 [01:28<107:28:07,  3.66s/it, 2021-01-14 08:31:10.378671 | Train Loss: 12.779664993286133 | Steps: 105826]\u001b[A\n","Epoch-1 Iterator:   0% 24/105802 [01:32<107:28:07,  3.66s/it, 2021-01-14 08:31:17.738326 | Train Loss: 12.949238300323486 | Steps: 105828]\u001b[A\n","Epoch-1 Iterator:   0% 25/105802 [01:32<108:46:02,  3.70s/it, 2021-01-14 08:31:17.738326 | Train Loss: 12.949238300323486 | Steps: 105828]\u001b[A\n","Epoch-1 Iterator:   0% 26/105802 [01:36<107:18:52,  3.65s/it, 2021-01-14 08:31:17.738326 | Train Loss: 12.949238300323486 | Steps: 105828]\u001b[A\n","Epoch-1 Iterator:   0% 26/105802 [01:39<107:18:52,  3.65s/it, 2021-01-14 08:31:25.088779 | Train Loss: 13.061620712280273 | Steps: 105830]\u001b[A\n","Epoch-1 Iterator:   0% 27/105802 [01:40<108:53:24,  3.71s/it, 2021-01-14 08:31:25.088779 | Train Loss: 13.061620712280273 | Steps: 105830]\u001b[A\n","Epoch-1 Iterator:   0% 28/105802 [01:43<107:37:07,  3.66s/it, 2021-01-14 08:31:25.088779 | Train Loss: 13.061620712280273 | Steps: 105830]\u001b[A\n","Epoch-1 Iterator:   0% 28/105802 [01:47<107:37:07,  3.66s/it, 2021-01-14 08:31:33.014085 | Train Loss: 13.191808700561523 | Steps: 105832]\u001b[A\n","Epoch-1 Iterator:   0% 29/105802 [01:47<113:42:39,  3.87s/it, 2021-01-14 08:31:33.014085 | Train Loss: 13.191808700561523 | Steps: 105832]\u001b[A\n","Epoch-1 Iterator:   0% 30/105802 [01:51<110:42:06,  3.77s/it, 2021-01-14 08:31:33.014085 | Train Loss: 13.191808700561523 | Steps: 105832]\u001b[A\n","Epoch-1 Iterator:   0% 30/105802 [01:54<110:42:06,  3.77s/it, 2021-01-14 08:31:40.389410 | Train Loss: 12.746142864227295 | Steps: 105834]\u001b[A\n","Epoch-1 Iterator:   0% 31/105802 [01:55<111:25:23,  3.79s/it, 2021-01-14 08:31:40.389410 | Train Loss: 12.746142864227295 | Steps: 105834]\u001b[A\n","Epoch-1 Iterator:   0% 32/105802 [01:58<109:37:08,  3.73s/it, 2021-01-14 08:31:40.389410 | Train Loss: 12.746142864227295 | Steps: 105834]\u001b[A\n","Epoch-1 Iterator:   0% 32/105802 [02:02<109:37:08,  3.73s/it, 2021-01-14 08:31:47.820299 | Train Loss: 12.830726146697998 | Steps: 105836]\u001b[A\n","Epoch-1 Iterator:   0% 33/105802 [02:02<110:48:47,  3.77s/it, 2021-01-14 08:31:47.820299 | Train Loss: 12.830726146697998 | Steps: 105836]\u001b[A\n","Epoch-1 Iterator:   0% 34/105802 [02:06<109:25:48,  3.72s/it, 2021-01-14 08:31:47.820299 | Train Loss: 12.830726146697998 | Steps: 105836]\u001b[A\n","Epoch-1 Iterator:   0% 34/105802 [02:09<109:25:48,  3.72s/it, 2021-01-14 08:31:55.298211 | Train Loss: 13.080506324768066 | Steps: 105838]\u001b[A\n","Epoch-1 Iterator:   0% 35/105802 [02:10<110:25:42,  3.76s/it, 2021-01-14 08:31:55.298211 | Train Loss: 13.080506324768066 | Steps: 105838]\u001b[A\n","Epoch-1 Iterator:   0% 36/105802 [02:13<108:35:09,  3.70s/it, 2021-01-14 08:31:55.298211 | Train Loss: 13.080506324768066 | Steps: 105838]\u001b[A\n","Epoch-1 Iterator:   0% 36/105802 [02:17<108:35:09,  3.70s/it, 2021-01-14 08:32:02.706783 | Train Loss: 12.927318096160889 | Steps: 105840]\u001b[A\n","Epoch-1 Iterator:   0% 37/105802 [02:17<110:02:51,  3.75s/it, 2021-01-14 08:32:02.706783 | Train Loss: 12.927318096160889 | Steps: 105840]\u001b[A\n","Epoch-1 Iterator:   0% 38/105802 [02:21<109:18:46,  3.72s/it, 2021-01-14 08:32:02.706783 | Train Loss: 12.927318096160889 | Steps: 105840]\u001b[A\n","Epoch-1 Iterator:   0% 38/105802 [02:24<109:18:46,  3.72s/it, 2021-01-14 08:32:10.218247 | Train Loss: 12.476110458374023 | Steps: 105842]\u001b[A\n","Epoch-1 Iterator:   0% 39/105802 [02:25<110:30:12,  3.76s/it, 2021-01-14 08:32:10.218247 | Train Loss: 12.476110458374023 | Steps: 105842]\u001b[A\n","Epoch-1 Iterator:   0% 40/105802 [02:28<108:43:50,  3.70s/it, 2021-01-14 08:32:10.218247 | Train Loss: 12.476110458374023 | Steps: 105842]\u001b[A\n","Epoch-1 Iterator:   0% 40/105802 [02:32<108:43:50,  3.70s/it, 2021-01-14 08:32:17.638768 | Train Loss: 12.788435935974121 | Steps: 105844]\u001b[A\n","Epoch-1 Iterator:   0% 41/105802 [02:32<110:05:52,  3.75s/it, 2021-01-14 08:32:17.638768 | Train Loss: 12.788435935974121 | Steps: 105844]\u001b[A\n","Epoch-1 Iterator:   0% 42/105802 [02:36<108:35:45,  3.70s/it, 2021-01-14 08:32:17.638768 | Train Loss: 12.788435935974121 | Steps: 105844]\u001b[A\n","Epoch-1 Iterator:   0% 42/105802 [02:39<108:35:45,  3.70s/it, 2021-01-14 08:32:25.071450 | Train Loss: 13.004443168640137 | Steps: 105846]\u001b[A\n","Epoch-1 Iterator:   0% 43/105802 [02:39<110:01:28,  3.75s/it, 2021-01-14 08:32:25.071450 | Train Loss: 13.004443168640137 | Steps: 105846]\u001b[A\n","Epoch-1 Iterator:   0% 44/105802 [02:43<108:16:56,  3.69s/it, 2021-01-14 08:32:25.071450 | Train Loss: 13.004443168640137 | Steps: 105846]\u001b[A\n","Epoch-1 Iterator:   0% 44/105802 [02:47<108:16:56,  3.69s/it, 2021-01-14 08:32:32.459658 | Train Loss: 12.568385124206543 | Steps: 105848]\u001b[A\n","Epoch-1 Iterator:   0% 45/105802 [02:47<109:34:11,  3.73s/it, 2021-01-14 08:32:32.459658 | Train Loss: 12.568385124206543 | Steps: 105848]\u001b[A\n","Epoch-1 Iterator:   0% 46/105802 [02:50<107:53:11,  3.67s/it, 2021-01-14 08:32:32.459658 | Train Loss: 12.568385124206543 | Steps: 105848]\u001b[A\n","Epoch-1 Iterator:   0% 46/105802 [02:54<107:53:11,  3.67s/it, 2021-01-14 08:32:39.856262 | Train Loss: 12.975504875183105 | Steps: 105850]\u001b[A\n","Epoch-1 Iterator:   0% 47/105802 [02:54<109:36:21,  3.73s/it, 2021-01-14 08:32:39.856262 | Train Loss: 12.975504875183105 | Steps: 105850]\u001b[A\n","Epoch-1 Iterator:   0% 48/105802 [02:58<108:02:51,  3.68s/it, 2021-01-14 08:32:39.856262 | Train Loss: 12.975504875183105 | Steps: 105850]\u001b[A\n","Epoch-1 Iterator:   0% 48/105802 [03:01<108:02:51,  3.68s/it, 2021-01-14 08:32:47.258878 | Train Loss: 13.188105583190918 | Steps: 105852]\u001b[A\n","Epoch-1 Iterator:   0% 49/105802 [03:02<109:26:24,  3.73s/it, 2021-01-14 08:32:47.258878 | Train Loss: 13.188105583190918 | Steps: 105852]\u001b[A\n","Epoch-1 Iterator:   0% 50/105802 [03:05<107:42:35,  3.67s/it, 2021-01-14 08:32:47.258878 | Train Loss: 13.188105583190918 | Steps: 105852]\u001b[A\n","Epoch-1 Iterator:   0% 50/105802 [03:09<107:42:35,  3.67s/it, 2021-01-14 08:32:54.620987 | Train Loss: 13.161959171295166 | Steps: 105854]\u001b[A\n","Epoch-1 Iterator:   0% 51/105802 [03:09<109:15:42,  3.72s/it, 2021-01-14 08:32:54.620987 | Train Loss: 13.161959171295166 | Steps: 105854]\u001b[A\n","Epoch-1 Iterator:   0% 52/105802 [03:13<107:46:50,  3.67s/it, 2021-01-14 08:32:54.620987 | Train Loss: 13.161959171295166 | Steps: 105854]\u001b[A\n","Epoch-1 Iterator:   0% 52/105802 [03:16<107:46:50,  3.67s/it, 2021-01-14 08:33:02.072523 | Train Loss: 13.337938785552979 | Steps: 105856]\u001b[A\n","Epoch-1 Iterator:   0% 53/105802 [03:16<109:50:55,  3.74s/it, 2021-01-14 08:33:02.072523 | Train Loss: 13.337938785552979 | Steps: 105856]\u001b[A\n","Epoch-1 Iterator:   0% 54/105802 [03:20<108:02:32,  3.68s/it, 2021-01-14 08:33:02.072523 | Train Loss: 13.337938785552979 | Steps: 105856]\u001b[A\n","Epoch-1 Iterator:   0% 54/105802 [03:24<108:02:32,  3.68s/it, 2021-01-14 08:33:09.450863 | Train Loss: 13.088303089141846 | Steps: 105858]\u001b[A\n","Epoch-1 Iterator:   0% 55/105802 [03:24<109:22:32,  3.72s/it, 2021-01-14 08:33:09.450863 | Train Loss: 13.088303089141846 | Steps: 105858]\u001b[A\n","Epoch-1 Iterator:   0% 56/105802 [03:28<109:20:49,  3.72s/it, 2021-01-14 08:33:09.450863 | Train Loss: 13.088303089141846 | Steps: 105858]\u001b[A\n","Epoch-1 Iterator:   0% 56/105802 [03:31<109:20:49,  3.72s/it, 2021-01-14 08:33:17.008900 | Train Loss: 12.66202449798584 | Steps: 105860] \u001b[A\n","Epoch-1 Iterator:   0% 57/105802 [03:31<110:33:56,  3.76s/it, 2021-01-14 08:33:17.008900 | Train Loss: 12.66202449798584 | Steps: 105860]\u001b[A\n","Epoch-1 Iterator:   0% 58/105802 [03:35<108:25:13,  3.69s/it, 2021-01-14 08:33:17.008900 | Train Loss: 12.66202449798584 | Steps: 105860]\u001b[A\n","Epoch-1 Iterator:   0% 58/105802 [03:38<108:25:13,  3.69s/it, 2021-01-14 08:33:24.365263 | Train Loss: 13.189440727233887 | Steps: 105862]\u001b[A\n","Epoch-1 Iterator:   0% 59/105802 [03:39<109:27:54,  3.73s/it, 2021-01-14 08:33:24.365263 | Train Loss: 13.189440727233887 | Steps: 105862]\u001b[A\n","Epoch-1 Iterator:   0% 60/105802 [03:42<107:51:00,  3.67s/it, 2021-01-14 08:33:24.365263 | Train Loss: 13.189440727233887 | Steps: 105862]\u001b[A\n","Epoch-1 Iterator:   0% 60/105802 [03:46<107:51:00,  3.67s/it, 2021-01-14 08:33:31.733090 | Train Loss: 13.323413848876953 | Steps: 105864]\u001b[A\n","Epoch-1 Iterator:   0% 61/105802 [03:46<109:16:30,  3.72s/it, 2021-01-14 08:33:31.733090 | Train Loss: 13.323413848876953 | Steps: 105864]\u001b[A\n","Epoch-1 Iterator:   0% 62/105802 [03:50<107:36:03,  3.66s/it, 2021-01-14 08:33:31.733090 | Train Loss: 13.323413848876953 | Steps: 105864]\u001b[A\n","Epoch-1 Iterator:   0% 62/105802 [03:53<107:36:03,  3.66s/it, 2021-01-14 08:33:39.088410 | Train Loss: 12.685790538787842 | Steps: 105866]\u001b[A\n","Epoch-1 Iterator:   0% 63/105802 [03:53<108:54:04,  3.71s/it, 2021-01-14 08:33:39.088410 | Train Loss: 12.685790538787842 | Steps: 105866]\u001b[A\n","Epoch-1 Iterator:   0% 64/105802 [03:57<107:21:33,  3.66s/it, 2021-01-14 08:33:39.088410 | Train Loss: 12.685790538787842 | Steps: 105866]\u001b[A\n","Epoch-1 Iterator:   0% 64/105802 [04:01<107:21:33,  3.66s/it, 2021-01-14 08:33:46.532462 | Train Loss: 13.452447414398193 | Steps: 105868]\u001b[A\n","Epoch-1 Iterator:   0% 65/105802 [04:01<109:42:10,  3.74s/it, 2021-01-14 08:33:46.532462 | Train Loss: 13.452447414398193 | Steps: 105868]\u001b[A\n","Epoch-1 Iterator:   0% 66/105802 [04:04<108:06:24,  3.68s/it, 2021-01-14 08:33:46.532462 | Train Loss: 13.452447414398193 | Steps: 105868]\u001b[A\n","Epoch-1 Iterator:   0% 66/105802 [04:08<108:06:24,  3.68s/it, 2021-01-14 08:33:53.907559 | Train Loss: 13.10528039932251 | Steps: 105870] \u001b[A\n","Epoch-1 Iterator:   0% 67/105802 [04:08<109:27:29,  3.73s/it, 2021-01-14 08:33:53.907559 | Train Loss: 13.10528039932251 | Steps: 105870]\u001b[A\n","Epoch-1 Iterator:   0% 68/105802 [04:12<109:38:20,  3.73s/it, 2021-01-14 08:33:53.907559 | Train Loss: 13.10528039932251 | Steps: 105870]\u001b[A\n","Epoch-1 Iterator:   0% 68/105802 [04:16<109:38:20,  3.73s/it, 2021-01-14 08:34:01.515217 | Train Loss: 12.468047618865967 | Steps: 105872]\u001b[A\n","Epoch-1 Iterator:   0% 69/105802 [04:16<110:45:03,  3.77s/it, 2021-01-14 08:34:01.515217 | Train Loss: 12.468047618865967 | Steps: 105872]\u001b[A\n","Epoch-1 Iterator:   0% 70/105802 [04:20<108:56:44,  3.71s/it, 2021-01-14 08:34:01.515217 | Train Loss: 12.468047618865967 | Steps: 105872]\u001b[A\n","Epoch-1 Iterator:   0% 70/105802 [04:23<108:56:44,  3.71s/it, 2021-01-14 08:34:08.920523 | Train Loss: 13.175867080688477 | Steps: 105874]\u001b[A\n","Epoch-1 Iterator:   0% 71/105802 [04:23<109:59:34,  3.75s/it, 2021-01-14 08:34:08.920523 | Train Loss: 13.175867080688477 | Steps: 105874]\u001b[A\n","Epoch-1 Iterator:   0% 72/105802 [04:27<108:12:27,  3.68s/it, 2021-01-14 08:34:08.920523 | Train Loss: 13.175867080688477 | Steps: 105874]\u001b[A\n","Epoch-1 Iterator:   0% 72/105802 [04:30<108:12:27,  3.68s/it, 2021-01-14 08:34:16.339433 | Train Loss: 13.0338716506958 | Steps: 105876]  \u001b[A\n","Epoch-1 Iterator:   0% 73/105802 [04:31<109:54:29,  3.74s/it, 2021-01-14 08:34:16.339433 | Train Loss: 13.0338716506958 | Steps: 105876]\u001b[A\n","Epoch-1 Iterator:   0% 74/105802 [04:34<108:13:19,  3.68s/it, 2021-01-14 08:34:16.339433 | Train Loss: 13.0338716506958 | Steps: 105876]\u001b[A\n","Epoch-1 Iterator:   0% 74/105802 [04:38<108:13:19,  3.68s/it, 2021-01-14 08:34:23.718056 | Train Loss: 13.248459815979004 | Steps: 105878]\u001b[A\n","Epoch-1 Iterator:   0% 75/105802 [04:38<109:24:20,  3.73s/it, 2021-01-14 08:34:23.718056 | Train Loss: 13.248459815979004 | Steps: 105878]\u001b[A\n","Epoch-1 Iterator:   0% 76/105802 [04:42<107:49:47,  3.67s/it, 2021-01-14 08:34:23.718056 | Train Loss: 13.248459815979004 | Steps: 105878]\u001b[A\n","Epoch-1 Iterator:   0% 76/105802 [04:45<107:49:47,  3.67s/it, 2021-01-14 08:34:31.081454 | Train Loss: 13.766473293304443 | Steps: 105880]\u001b[A\n","Epoch-1 Iterator:   0% 77/105802 [04:45<109:02:25,  3.71s/it, 2021-01-14 08:34:31.081454 | Train Loss: 13.766473293304443 | Steps: 105880]\u001b[A\n","Epoch-1 Iterator:   0% 78/105802 [04:49<107:19:34,  3.65s/it, 2021-01-14 08:34:31.081454 | Train Loss: 13.766473293304443 | Steps: 105880]\u001b[A\n","Epoch-1 Iterator:   0% 78/105802 [04:53<107:19:34,  3.65s/it, 2021-01-14 08:34:38.415000 | Train Loss: 13.118199825286865 | Steps: 105882]\u001b[A\n","Epoch-1 Iterator:   0% 79/105802 [04:53<108:45:22,  3.70s/it, 2021-01-14 08:34:38.415000 | Train Loss: 13.118199825286865 | Steps: 105882]\u001b[A\n","Epoch-1 Iterator:   0% 80/105802 [04:56<107:04:34,  3.65s/it, 2021-01-14 08:34:38.415000 | Train Loss: 13.118199825286865 | Steps: 105882]\u001b[A\n","Epoch-1 Iterator:   0% 80/105802 [05:00<107:04:34,  3.65s/it, 2021-01-14 08:34:45.738051 | Train Loss: 12.79313039779663 | Steps: 105884] \u001b[A\n","Epoch-1 Iterator:   0% 81/105802 [05:00<108:40:43,  3.70s/it, 2021-01-14 08:34:45.738051 | Train Loss: 12.79313039779663 | Steps: 105884]\u001b[A\n","Epoch-1 Iterator:   0% 82/105802 [05:04<107:06:23,  3.65s/it, 2021-01-14 08:34:45.738051 | Train Loss: 12.79313039779663 | Steps: 105884]\u001b[A\n","Epoch-1 Iterator:   0% 82/105802 [05:07<107:06:23,  3.65s/it, 2021-01-14 08:34:53.107581 | Train Loss: 13.279919624328613 | Steps: 105886]\u001b[A\n","Epoch-1 Iterator:   0% 83/105802 [05:08<108:48:39,  3.71s/it, 2021-01-14 08:34:53.107581 | Train Loss: 13.279919624328613 | Steps: 105886]\u001b[A\n","Epoch-1 Iterator:   0% 84/105802 [05:11<107:43:50,  3.67s/it, 2021-01-14 08:34:53.107581 | Train Loss: 13.279919624328613 | Steps: 105886]\u001b[A\n","Epoch-1 Iterator:   0% 84/105802 [05:15<107:43:50,  3.67s/it, 2021-01-14 08:35:00.527884 | Train Loss: 12.044926166534424 | Steps: 105888]\u001b[A\n","Epoch-1 Iterator:   0% 85/105802 [05:15<109:13:18,  3.72s/it, 2021-01-14 08:35:00.527884 | Train Loss: 12.044926166534424 | Steps: 105888]\u001b[A\n","Epoch-1 Iterator:   0% 86/105802 [05:18<107:38:38,  3.67s/it, 2021-01-14 08:35:00.527884 | Train Loss: 12.044926166534424 | Steps: 105888]\u001b[A\n","Epoch-1 Iterator:   0% 86/105802 [05:22<107:38:38,  3.67s/it, 2021-01-14 08:35:07.920131 | Train Loss: 13.268442630767822 | Steps: 105890]\u001b[A\n","Epoch-1 Iterator:   0% 87/105802 [05:22<109:16:58,  3.72s/it, 2021-01-14 08:35:07.920131 | Train Loss: 13.268442630767822 | Steps: 105890]\u001b[A\n","Epoch-1 Iterator:   0% 88/105802 [05:26<107:30:07,  3.66s/it, 2021-01-14 08:35:07.920131 | Train Loss: 13.268442630767822 | Steps: 105890]\u001b[A\n","Epoch-1 Iterator:   0% 88/105802 [05:29<107:30:07,  3.66s/it, 2021-01-14 08:35:15.265625 | Train Loss: 13.4288330078125 | Steps: 105892]  \u001b[A\n","Epoch-1 Iterator:   0% 89/105802 [05:30<108:51:03,  3.71s/it, 2021-01-14 08:35:15.265625 | Train Loss: 13.4288330078125 | Steps: 105892]\u001b[A\n","Epoch-1 Iterator:   0% 90/105802 [05:33<107:14:57,  3.65s/it, 2021-01-14 08:35:15.265625 | Train Loss: 13.4288330078125 | Steps: 105892]\u001b[A\n","Epoch-1 Iterator:   0% 90/105802 [05:37<107:14:57,  3.65s/it, 2021-01-14 08:35:22.621743 | Train Loss: 13.180453300476074 | Steps: 105894]\u001b[A\n","Epoch-1 Iterator:   0% 91/105802 [05:37<108:57:06,  3.71s/it, 2021-01-14 08:35:22.621743 | Train Loss: 13.180453300476074 | Steps: 105894]\u001b[A\n","Epoch-1 Iterator:   0% 92/105802 [05:41<107:25:16,  3.66s/it, 2021-01-14 08:35:22.621743 | Train Loss: 13.180453300476074 | Steps: 105894]\u001b[A\n","Epoch-1 Iterator:   0% 92/105802 [05:44<107:25:16,  3.66s/it, 2021-01-14 08:35:29.966572 | Train Loss: 13.108285903930664 | Steps: 105896]\u001b[A\n","Epoch-1 Iterator:   0% 93/105802 [05:44<108:40:47,  3.70s/it, 2021-01-14 08:35:29.966572 | Train Loss: 13.108285903930664 | Steps: 105896]\u001b[A\n","Epoch-1 Iterator:   0% 94/105802 [05:48<107:08:39,  3.65s/it, 2021-01-14 08:35:29.966572 | Train Loss: 13.108285903930664 | Steps: 105896]\u001b[A\n","Epoch-1 Iterator:   0% 94/105802 [05:51<107:08:39,  3.65s/it, 2021-01-14 08:35:37.310427 | Train Loss: 12.837061882019043 | Steps: 105898]\u001b[A\n","Epoch-1 Iterator:   0% 95/105802 [05:52<108:35:48,  3.70s/it, 2021-01-14 08:35:37.310427 | Train Loss: 12.837061882019043 | Steps: 105898]\u001b[A\n","Epoch-1 Iterator:   0% 96/105802 [05:55<107:08:52,  3.65s/it, 2021-01-14 08:35:37.310427 | Train Loss: 12.837061882019043 | Steps: 105898]\u001b[A\n","Epoch-1 Iterator:   0% 96/105802 [05:59<107:08:52,  3.65s/it, 2021-01-14 08:35:44.653968 | Train Loss: 12.687321662902832 | Steps: 105900]\u001b[A\n","Epoch-1 Iterator:   0% 97/105802 [06:02<134:52:04,  4.59s/it, 2021-01-14 08:35:44.653968 | Train Loss: 12.687321662902832 | Steps: 105900]\u001b[A\n","Epoch-1 Iterator:   0% 98/105802 [06:06<126:35:11,  4.31s/it, 2021-01-14 08:35:44.653968 | Train Loss: 12.687321662902832 | Steps: 105900]\u001b[A\n","Epoch-1 Iterator:   0% 98/105802 [06:09<126:35:11,  4.31s/it, 2021-01-14 08:35:55.120131 | Train Loss: 12.772871494293213 | Steps: 105902]\u001b[A\n","Epoch-1 Iterator:   0% 99/105802 [06:10<122:53:56,  4.19s/it, 2021-01-14 08:35:55.120131 | Train Loss: 12.772871494293213 | Steps: 105902]\u001b[A\n","Epoch-1 Iterator:   0% 100/105802 [06:13<117:45:23,  4.01s/it, 2021-01-14 08:35:55.120131 | Train Loss: 12.772871494293213 | Steps: 105902]\u001b[A\n","Epoch-1 Iterator:   0% 100/105802 [06:17<117:45:23,  4.01s/it, 2021-01-14 08:36:02.786285 | Train Loss: 13.265416145324707 | Steps: 105904]\u001b[A\n","Epoch-1 Iterator:   0% 101/105802 [06:17<117:59:43,  4.02s/it, 2021-01-14 08:36:02.786285 | Train Loss: 13.265416145324707 | Steps: 105904]\u001b[A\n","Epoch-1 Iterator:   0% 102/105802 [06:21<114:07:06,  3.89s/it, 2021-01-14 08:36:02.786285 | Train Loss: 13.265416145324707 | Steps: 105904]\u001b[A\n","Epoch-1 Iterator:   0% 102/105802 [06:24<114:07:06,  3.89s/it, 2021-01-14 08:36:10.262020 | Train Loss: 12.93066930770874 | Steps: 105906] \u001b[A\n","Epoch-1 Iterator:   0% 103/105802 [06:25<114:01:23,  3.88s/it, 2021-01-14 08:36:10.262020 | Train Loss: 12.93066930770874 | Steps: 105906]\u001b[A\n","Epoch-1 Iterator:   0% 104/105802 [06:28<111:39:23,  3.80s/it, 2021-01-14 08:36:10.262020 | Train Loss: 12.93066930770874 | Steps: 105906]\u001b[A\n","Epoch-1 Iterator:   0% 104/105802 [06:32<111:39:23,  3.80s/it, 2021-01-14 08:36:17.785733 | Train Loss: 12.5206937789917 | Steps: 105908] \u001b[A\n","Epoch-1 Iterator:   0% 105/105802 [06:32<112:35:02,  3.83s/it, 2021-01-14 08:36:17.785733 | Train Loss: 12.5206937789917 | Steps: 105908]\u001b[A\n","Epoch-1 Iterator:   0% 106/105802 [06:36<109:51:24,  3.74s/it, 2021-01-14 08:36:17.785733 | Train Loss: 12.5206937789917 | Steps: 105908]\u001b[A\n","Epoch-1 Iterator:   0% 106/105802 [06:39<109:51:24,  3.74s/it, 2021-01-14 08:36:25.145645 | Train Loss: 12.84226942062378 | Steps: 105910]\u001b[A\n","Epoch-1 Iterator:   0% 107/105802 [06:40<110:42:24,  3.77s/it, 2021-01-14 08:36:25.145645 | Train Loss: 12.84226942062378 | Steps: 105910]\u001b[A\n","Epoch-1 Iterator:   0% 108/105802 [06:43<108:44:43,  3.70s/it, 2021-01-14 08:36:25.145645 | Train Loss: 12.84226942062378 | Steps: 105910]\u001b[A\n","Epoch-1 Iterator:   0% 108/105802 [06:47<108:44:43,  3.70s/it, 2021-01-14 08:36:32.585455 | Train Loss: 13.241329193115234 | Steps: 105912]\u001b[A\n","Epoch-1 Iterator:   0% 109/105802 [06:47<110:14:22,  3.75s/it, 2021-01-14 08:36:32.585455 | Train Loss: 13.241329193115234 | Steps: 105912]\u001b[A\n","Epoch-1 Iterator:   0% 110/105802 [06:51<108:18:05,  3.69s/it, 2021-01-14 08:36:32.585455 | Train Loss: 13.241329193115234 | Steps: 105912]\u001b[A\n","Epoch-1 Iterator:   0% 110/105802 [06:54<108:18:05,  3.69s/it, 2021-01-14 08:36:39.922199 | Train Loss: 12.992524147033691 | Steps: 105914]\u001b[A\n","Epoch-1 Iterator:   0% 111/105802 [06:54<109:22:03,  3.73s/it, 2021-01-14 08:36:39.922199 | Train Loss: 12.992524147033691 | Steps: 105914]\u001b[A\n","Epoch-1 Iterator:   0% 112/105802 [06:58<107:56:44,  3.68s/it, 2021-01-14 08:36:39.922199 | Train Loss: 12.992524147033691 | Steps: 105914]\u001b[A\n","Epoch-1 Iterator:   0% 112/105802 [07:01<107:56:44,  3.68s/it, 2021-01-14 08:36:47.343574 | Train Loss: 12.774291515350342 | Steps: 105916]\u001b[A\n","Epoch-1 Iterator:   0% 113/105802 [07:02<109:33:06,  3.73s/it, 2021-01-14 08:36:47.343574 | Train Loss: 12.774291515350342 | Steps: 105916]\u001b[A\n","Epoch-1 Iterator:   0% 114/105802 [07:05<108:01:12,  3.68s/it, 2021-01-14 08:36:47.343574 | Train Loss: 12.774291515350342 | Steps: 105916]\u001b[A\n","Epoch-1 Iterator:   0% 114/105802 [07:09<108:01:12,  3.68s/it, 2021-01-14 08:36:54.896072 | Train Loss: 12.842771530151367 | Steps: 105918]\u001b[A\n","Epoch-1 Iterator:   0% 115/105802 [07:09<110:48:01,  3.77s/it, 2021-01-14 08:36:54.896072 | Train Loss: 12.842771530151367 | Steps: 105918]\u001b[A\n","Epoch-1 Iterator:   0% 116/105802 [07:13<108:38:12,  3.70s/it, 2021-01-14 08:36:54.896072 | Train Loss: 12.842771530151367 | Steps: 105918]\u001b[A\n","Epoch-1 Iterator:   0% 116/105802 [07:16<108:38:12,  3.70s/it, 2021-01-14 08:37:02.279683 | Train Loss: 13.525556087493896 | Steps: 105920]\u001b[A\n","Epoch-1 Iterator:   0% 117/105802 [07:17<109:56:33,  3.75s/it, 2021-01-14 08:37:02.279683 | Train Loss: 13.525556087493896 | Steps: 105920]\u001b[A\n","Epoch-1 Iterator:   0% 118/105802 [07:20<108:09:37,  3.68s/it, 2021-01-14 08:37:02.279683 | Train Loss: 13.525556087493896 | Steps: 105920]\u001b[A\n","Epoch-1 Iterator:   0% 118/105802 [07:24<108:09:37,  3.68s/it, 2021-01-14 08:37:09.683470 | Train Loss: 13.162115097045898 | Steps: 105922]\u001b[A\n","Epoch-1 Iterator:   0% 119/105802 [07:24<109:45:55,  3.74s/it, 2021-01-14 08:37:09.683470 | Train Loss: 13.162115097045898 | Steps: 105922]\u001b[A\n","Epoch-1 Iterator:   0% 120/105802 [07:28<107:54:55,  3.68s/it, 2021-01-14 08:37:09.683470 | Train Loss: 13.162115097045898 | Steps: 105922]\u001b[A\n","Epoch-1 Iterator:   0% 120/105802 [07:32<107:54:55,  3.68s/it, 2021-01-14 08:37:17.426440 | Train Loss: 13.348546981811523 | Steps: 105924]\u001b[A\n","Epoch-1 Iterator:   0% 121/105802 [07:32<112:44:52,  3.84s/it, 2021-01-14 08:37:17.426440 | Train Loss: 13.348546981811523 | Steps: 105924]\u001b[A\n","Epoch-1 Iterator:   0% 122/105802 [07:35<110:08:41,  3.75s/it, 2021-01-14 08:37:17.426440 | Train Loss: 13.348546981811523 | Steps: 105924]\u001b[A\n","Epoch-1 Iterator:   0% 122/105802 [07:39<110:08:41,  3.75s/it, 2021-01-14 08:37:24.823235 | Train Loss: 12.92488718032837 | Steps: 105926] \u001b[A\n","Epoch-1 Iterator:   0% 123/105802 [07:39<110:56:14,  3.78s/it, 2021-01-14 08:37:24.823235 | Train Loss: 12.92488718032837 | Steps: 105926]\u001b[A\n","Epoch-1 Iterator:   0% 124/105802 [07:43<108:48:58,  3.71s/it, 2021-01-14 08:37:24.823235 | Train Loss: 12.92488718032837 | Steps: 105926]\u001b[A\n","Epoch-1 Iterator:   0% 124/105802 [07:46<108:48:58,  3.71s/it, 2021-01-14 08:37:32.316556 | Train Loss: 13.39955472946167 | Steps: 105928]\u001b[A\n","Epoch-1 Iterator:   0% 125/105802 [07:47<111:02:36,  3.78s/it, 2021-01-14 08:37:32.316556 | Train Loss: 13.39955472946167 | Steps: 105928]\u001b[A\n","Epoch-1 Iterator:   0% 126/105802 [07:50<109:53:28,  3.74s/it, 2021-01-14 08:37:32.316556 | Train Loss: 13.39955472946167 | Steps: 105928]\u001b[A\n","Epoch-1 Iterator:   0% 126/105802 [07:54<109:53:28,  3.74s/it, 2021-01-14 08:37:39.809522 | Train Loss: 13.379517078399658 | Steps: 105930]\u001b[A\n","Epoch-1 Iterator:   0% 127/105802 [07:54<110:39:05,  3.77s/it, 2021-01-14 08:37:39.809522 | Train Loss: 13.379517078399658 | Steps: 105930]\u001b[A\n","Epoch-1 Iterator:   0% 128/105802 [07:58<108:45:38,  3.71s/it, 2021-01-14 08:37:39.809522 | Train Loss: 13.379517078399658 | Steps: 105930]\u001b[A\n","Epoch-1 Iterator:   0% 128/105802 [08:01<108:45:38,  3.71s/it, 2021-01-14 08:37:47.211682 | Train Loss: 12.517443656921387 | Steps: 105932]\u001b[A\n","Epoch-1 Iterator:   0% 129/105802 [08:02<110:07:24,  3.75s/it, 2021-01-14 08:37:47.211682 | Train Loss: 12.517443656921387 | Steps: 105932]\u001b[A\n","Epoch-1 Iterator:   0% 130/105802 [08:05<108:13:30,  3.69s/it, 2021-01-14 08:37:47.211682 | Train Loss: 12.517443656921387 | Steps: 105932]\u001b[A\n","Epoch-1 Iterator:   0% 130/105802 [08:09<108:13:30,  3.69s/it, 2021-01-14 08:37:54.609297 | Train Loss: 13.243057250976562 | Steps: 105934]\u001b[A\n","Epoch-1 Iterator:   0% 131/105802 [08:09<109:40:35,  3.74s/it, 2021-01-14 08:37:54.609297 | Train Loss: 13.243057250976562 | Steps: 105934]\u001b[A\n","Epoch-1 Iterator:   0% 132/105802 [08:13<107:50:46,  3.67s/it, 2021-01-14 08:37:54.609297 | Train Loss: 13.243057250976562 | Steps: 105934]\u001b[A\n","Epoch-1 Iterator:   0% 132/105802 [08:16<107:50:46,  3.67s/it, 2021-01-14 08:38:02.000604 | Train Loss: 12.685119152069092 | Steps: 105936]\u001b[A\n","Epoch-1 Iterator:   0% 133/105802 [08:16<109:32:55,  3.73s/it, 2021-01-14 08:38:02.000604 | Train Loss: 12.685119152069092 | Steps: 105936]\u001b[A\n","Epoch-1 Iterator:   0% 134/105802 [08:20<111:13:19,  3.79s/it, 2021-01-14 08:38:02.000604 | Train Loss: 12.685119152069092 | Steps: 105936]\u001b[A\n","Epoch-1 Iterator:   0% 134/105802 [08:24<111:13:19,  3.79s/it, 2021-01-14 08:38:09.833397 | Train Loss: 13.123273849487305 | Steps: 105938]\u001b[A\n","Epoch-1 Iterator:   0% 135/105802 [08:24<112:20:38,  3.83s/it, 2021-01-14 08:38:09.833397 | Train Loss: 13.123273849487305 | Steps: 105938]\u001b[A\n","Epoch-1 Iterator:   0% 136/105802 [08:28<109:57:10,  3.75s/it, 2021-01-14 08:38:09.833397 | Train Loss: 13.123273849487305 | Steps: 105938]\u001b[A\n","Epoch-1 Iterator:   0% 136/105802 [08:31<109:57:10,  3.75s/it, 2021-01-14 08:38:17.284550 | Train Loss: 13.029674530029297 | Steps: 105940]\u001b[A\n","Epoch-1 Iterator:   0% 137/105802 [08:32<111:15:14,  3.79s/it, 2021-01-14 08:38:17.284550 | Train Loss: 13.029674530029297 | Steps: 105940]\u001b[A\n","Epoch-1 Iterator:   0% 138/105802 [08:35<109:03:05,  3.72s/it, 2021-01-14 08:38:17.284550 | Train Loss: 13.029674530029297 | Steps: 105940]\u001b[A\n","Epoch-1 Iterator:   0% 138/105802 [08:39<109:03:05,  3.72s/it, 2021-01-14 08:38:24.668043 | Train Loss: 12.780056476593018 | Steps: 105942]\u001b[A\n","Epoch-1 Iterator:   0% 139/105802 [08:39<110:05:49,  3.75s/it, 2021-01-14 08:38:24.668043 | Train Loss: 12.780056476593018 | Steps: 105942]\u001b[A\n","Epoch-1 Iterator:   0% 140/105802 [08:43<108:07:42,  3.68s/it, 2021-01-14 08:38:24.668043 | Train Loss: 12.780056476593018 | Steps: 105942]\u001b[A\n","Epoch-1 Iterator:   0% 140/105802 [08:46<108:07:42,  3.68s/it, 2021-01-14 08:38:32.033606 | Train Loss: 13.323496341705322 | Steps: 105944]\u001b[A\n","Epoch-1 Iterator:   0% 141/105802 [08:46<109:30:36,  3.73s/it, 2021-01-14 08:38:32.033606 | Train Loss: 13.323496341705322 | Steps: 105944]\u001b[A\n","Epoch-1 Iterator:   0% 142/105802 [08:50<107:52:02,  3.68s/it, 2021-01-14 08:38:32.033606 | Train Loss: 13.323496341705322 | Steps: 105944]\u001b[A\n","Epoch-1 Iterator:   0% 142/105802 [08:54<107:52:02,  3.68s/it, 2021-01-14 08:38:39.418571 | Train Loss: 12.937520503997803 | Steps: 105946]\u001b[A\n","Epoch-1 Iterator:   0% 143/105802 [08:54<109:18:44,  3.72s/it, 2021-01-14 08:38:39.418571 | Train Loss: 12.937520503997803 | Steps: 105946]\u001b[A\n","Epoch-1 Iterator:   0% 144/105802 [08:57<108:04:54,  3.68s/it, 2021-01-14 08:38:39.418571 | Train Loss: 12.937520503997803 | Steps: 105946]\u001b[A\n","Epoch-1 Iterator:   0% 144/105802 [09:01<108:04:54,  3.68s/it, 2021-01-14 08:38:46.855704 | Train Loss: 13.448995590209961 | Steps: 105948]\u001b[A\n","Epoch-1 Iterator:   0% 145/105802 [09:01<109:34:22,  3.73s/it, 2021-01-14 08:38:46.855704 | Train Loss: 13.448995590209961 | Steps: 105948]\u001b[A\n","Epoch-1 Iterator:   0% 146/105802 [09:05<107:56:17,  3.68s/it, 2021-01-14 08:38:46.855704 | Train Loss: 13.448995590209961 | Steps: 105948]\u001b[A\n","Epoch-1 Iterator:   0% 146/105802 [09:08<107:56:17,  3.68s/it, 2021-01-14 08:38:54.280383 | Train Loss: 12.760632514953613 | Steps: 105950]\u001b[A\n","Epoch-1 Iterator:   0% 147/105802 [09:09<109:41:41,  3.74s/it, 2021-01-14 08:38:54.280383 | Train Loss: 12.760632514953613 | Steps: 105950]\u001b[A\n","Epoch-1 Iterator:   0% 148/105802 [09:12<108:02:28,  3.68s/it, 2021-01-14 08:38:54.280383 | Train Loss: 12.760632514953613 | Steps: 105950]\u001b[A\n","Epoch-1 Iterator:   0% 148/105802 [09:16<108:02:28,  3.68s/it, 2021-01-14 08:39:01.684131 | Train Loss: 13.399502277374268 | Steps: 105952]\u001b[A\n","Epoch-1 Iterator:   0% 149/105802 [09:16<109:35:29,  3.73s/it, 2021-01-14 08:39:01.684131 | Train Loss: 13.399502277374268 | Steps: 105952]\u001b[ATraceback (most recent call last):\n","  File \"/content/drive/My Drive/Colab Notebooks/reformer-language-model/pretrain/electra-model.py\", line 286, in <module>\n","    main()\n","  File \"/content/drive/My Drive/Colab Notebooks/reformer-language-model/pretrain/electra-model.py\", line 283, in main\n","    gradient_accumulation_steps=train_config.gradient_accumulation_steps)\n","  File \"/content/drive/My Drive/Colab Notebooks/reformer-language-model/pretrain/electra-model.py\", line 125, in train\n","    output = self.model(input_data)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/electra_pytorch/electra_pytorch.py\", line 209, in forward\n","    disc_logits = self.discriminator(disc_input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 117, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reformer_pytorch.py\", line 721, in forward\n","    x = self.reformer(x, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reformer_pytorch.py\", line 683, in forward\n","    x = self.layers(x, arg_route = arg_route, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reversible.py\", line 162, in forward\n","    return _ReversibleFunction.apply(x, blocks, block_kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reversible.py\", line 123, in forward\n","    x = block(x, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reversible.py\", line 59, in forward\n","    y1 = x1 + self.f(x2, record_rng=self.training, **f_args)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reversible.py\", line 27, in forward\n","    return self.net(*args, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reformer_pytorch.py\", line 147, in forward\n","    return self.fn(x, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reformer_pytorch.py\", line 562, in forward\n","    out, attn, buckets = attn_fn_in_chunks(qk, v, **masks)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reformer_pytorch.py\", line 36, in inner_fn\n","    outputs = [fn(*c_args, **c_kwargs) for c_args, c_kwargs in all_args]\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reformer_pytorch.py\", line 36, in <listcomp>\n","    outputs = [fn(*c_args, **c_kwargs) for c_args, c_kwargs in all_args]\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/reformer_pytorch/reformer_pytorch.py\", line 407, in forward\n","    probs = torch.exp(logits - torch.logsumexp(logits, dim=1, keepdim=True))\n","KeyboardInterrupt\n","\n","Epoch-0 Iterator: |          | 105803/? [8:22:00<00:00,  3.51it/s, 2021-01-14 05:05:37.916545 | Train Loss: 12.671985149383545 | Steps: 105802]\n","Epoch-1 Iterator:   0% 149/105802 [09:17<109:51:07,  3.74s/it, 2021-01-14 08:39:01.684131 | Train Loss: 13.399502277374268 | Steps: 105952]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sMocF9XuH4iF","executionInfo":{"status":"ok","timestamp":1610613548240,"user_tz":-540,"elapsed":30376595,"user":{"displayName":"Seonghwan Kim","photoUrl":"https://lh3.googleusercontent.com/-hgV3WUwRu5o/AAAAAAAAAAI/AAAAAAAAABo/_YWLMr5poWs/s64/photo.jpg","userId":"17497395371430681608"}}},"source":[""],"execution_count":4,"outputs":[]}]}